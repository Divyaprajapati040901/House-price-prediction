{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "r3c_sj4xj9aS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "data = pd.read_csv('/content/sqm_data.csv')\n",
        "\n",
        "# Drop specified columns\n",
        "data.drop(columns=['id', 'type', 'propertytype', 'flatnumber', 'state', 'geom',\n",
        "                   'street', 'property_id-2','streetnumber', 'suburb', 'latitude', 'longitude'], inplace=True)\n",
        "\n",
        "# Group by 'property_id' and calculate the mean price\n",
        "price_mean_by_property = data.groupby('property_id')['price'].transform('mean')\n",
        "\n",
        "# Fill NaN values in 'price' with the calculated mean for each 'property_id'\n",
        "data['price'].fillna(price_mean_by_property, inplace=True)\n",
        "\n",
        "# Drop rows where 'price' has NaN values\n",
        "data.dropna(subset=['price'], inplace=True)\n",
        "\n",
        "# Fill NaN values in 'carspaces' with 0\n",
        "data['carspaces'].fillna(0, inplace=True)\n",
        "\n",
        "# Drop rows where 'area' column has NaN values\n",
        "data.dropna(subset=['area'], inplace=True)\n",
        "\n",
        "# One-Hot Encoding for 'streettype'\n",
        "data = pd.get_dummies(data, columns=['streettype'], prefix='streettype', drop_first=True)\n",
        "\n",
        "# Convert 'date' to datetime and extract 'year', 'month', and 'day'\n",
        "data['date'] = pd.to_datetime(data['date'], errors='coerce')\n",
        "data['year'] = data['date'].dt.year\n",
        "data['month'] = data['date'].dt.month\n",
        "data['day'] = data['date'].dt.day\n",
        "\n",
        "# Drop the 'date' column\n",
        "data.drop(columns=['date'], inplace=True)\n",
        "\n",
        "# Standardize 'price' and 'area'\n",
        "scaler = StandardScaler()\n",
        "data[['price', 'area']] = scaler.fit_transform(data[['price', 'area']])\n",
        "\n",
        "# Target encoding for 'property_id'\n",
        "category_means = data.groupby('property_id')['price'].mean()\n",
        "data['property_id_target_encoded'] = data['property_id'].map(category_means)\n",
        "\n",
        "# Drop original 'property_id' column after encoding\n",
        "data.drop(columns=['property_id'], inplace=True)\n",
        "\n",
        "# Split the data\n",
        "X = data.drop(columns=['price'])\n",
        "y = data['price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "qDOaIF5m7-r7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823e72fd-7d9b-4e48-b2bd-1f54684f9d39"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-cf2a2fc81c52>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['price'].fillna(price_mean_by_property, inplace=True)\n",
            "<ipython-input-11-cf2a2fc81c52>:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['carspaces'].fillna(0, inplace=True)\n",
            "<ipython-input-11-cf2a2fc81c52>:27: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  data['date'] = pd.to_datetime(data['date'], errors='coerce')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming the previous steps to process and split the data are done\n",
        "# Your X_train, X_test, y_train, y_test are ready\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
        "    \"XGBoost\": XGBRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# Fit each model and calculate performance metrics\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions for test data\n",
        "    y_pred_test_scaled = model.predict(X_test)\n",
        "    # Predictions for train data\n",
        "    y_pred_train_scaled = model.predict(X_train)\n",
        "\n",
        "    # Inverse transform predictions and actual prices for test data\n",
        "    y_pred_test_original = scaler.inverse_transform(\n",
        "        np.column_stack((y_pred_test_scaled, np.zeros(len(y_pred_test_scaled))))\n",
        "    )[:, 0]\n",
        "    y_test_original = scaler.inverse_transform(\n",
        "        np.column_stack((y_test.values, np.zeros(len(y_test))))\n",
        "    )[:, 0]\n",
        "\n",
        "    # Inverse transform predictions and actual prices for train data\n",
        "    y_pred_train_original = scaler.inverse_transform(\n",
        "        np.column_stack((y_pred_train_scaled, np.zeros(len(y_pred_train_scaled))))\n",
        "    )[:, 0]\n",
        "    y_train_original = scaler.inverse_transform(\n",
        "        np.column_stack((y_train.values, np.zeros(len(y_train))))\n",
        "    )[:, 0]\n",
        "\n",
        "    # Calculate metrics for test data\n",
        "    mse_test = mean_squared_error(y_test_original, y_pred_test_original)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    r2_test = r2_score(y_test_original, y_pred_test_original)\n",
        "    mae_test = mean_absolute_error(y_test_original, y_pred_test_original)\n",
        "\n",
        "    # Calculate metrics for train data\n",
        "    mse_train = mean_squared_error(y_train_original, y_pred_train_original)\n",
        "    r2_train = r2_score(y_train_original, y_pred_train_original)\n",
        "\n",
        "    # Store the results\n",
        "    results[model_name] = {\n",
        "        \"MSE Test\": mse_test,\n",
        "        \"RMSE Test\": rmse_test,\n",
        "        \"R^2 Test\": r2_test,\n",
        "        \"MAE Test\": mae_test,\n",
        "        \"R^2 Train\": r2_train\n",
        "    }\n",
        "\n",
        "# Print results\n",
        "print(\"Performance metrics for each model:\")\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    for metric_name, value in metrics.items():\n",
        "        print(f\"  {metric_name}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWo3d7WRJoUz",
        "outputId": "c5f7052a-0a33-4b6d-8580-364a7559caeb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance metrics for each model:\n",
            "\n",
            "Linear Regression:\n",
            "  MSE Test: 32001173325.237865\n",
            "  RMSE Test: 178888.71771366094\n",
            "  R^2 Test: 0.8160020943003649\n",
            "  MAE Test: 109239.97202797746\n",
            "  R^2 Train: 0.814986323399788\n",
            "\n",
            "Random Forest:\n",
            "  MSE Test: 20290710749.726017\n",
            "  RMSE Test: 142445.46587984476\n",
            "  R^2 Test: 0.8833340188760435\n",
            "  MAE Test: 73266.86827658988\n",
            "  R^2 Train: 0.975453346560144\n",
            "\n",
            "Gradient Boosting:\n",
            "  MSE Test: 19699994738.339184\n",
            "  RMSE Test: 140356.66973229017\n",
            "  R^2 Test: 0.8867304727452114\n",
            "  MAE Test: 79341.42287314447\n",
            "  R^2 Train: 0.9095336472209172\n",
            "\n",
            "XGBoost:\n",
            "  MSE Test: 51047869502.64581\n",
            "  RMSE Test: 225937.755814839\n",
            "  R^2 Test: 0.7064888532850291\n",
            "  MAE Test: 80167.5287494293\n",
            "  R^2 Train: 0.9848576111098014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a dictionary to store actual vs predicted values for each model\n",
        "predictions_vs_actual = {}\n",
        "\n",
        "# Predicting actual prices for each model and comparing them\n",
        "for model_name, model in models.items():\n",
        "    # Predict on the test data\n",
        "    y_pred_test_scaled = model.predict(X_test)\n",
        "\n",
        "    # Inverse transform predictions and actual prices to get back to original scale\n",
        "    y_pred_test_original = scaler.inverse_transform(\n",
        "        np.column_stack((y_pred_test_scaled, np.zeros(len(y_pred_test_scaled))))\n",
        "    )[:, 0]\n",
        "    y_test_original = scaler.inverse_transform(\n",
        "        np.column_stack((y_test.values, np.zeros(len(y_test))))\n",
        "    )[:, 0]\n",
        "\n",
        "    # Store the results in the dictionary\n",
        "    predictions_vs_actual[model_name] = {\n",
        "        \"Actual Prices\": y_test_original.tolist(),\n",
        "        \"Predicted Prices\": y_pred_test_original.tolist()\n",
        "    }\n",
        "\n",
        "# Print sample results (10 values) for each model\n",
        "for model_name, values in predictions_vs_actual.items():\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(\"Sample of 10 Actual Prices vs Predicted Prices:\")\n",
        "    for actual, predicted in zip(values[\"Actual Prices\"][:10], values[\"Predicted Prices\"][:10]):\n",
        "        print(f\"  Actual: {actual:.2f}, Predicted: {predicted:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F8PkrXoJoSY",
        "outputId": "b2551c33-e0e7-4886-f36d-8c70e93f6fb0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Linear Regression:\n",
            "Sample of 10 Actual Prices vs Predicted Prices:\n",
            "  Actual: 420000.00, Predicted: 763147.69\n",
            "  Actual: 715000.00, Predicted: 789303.34\n",
            "  Actual: 250000.00, Predicted: 406026.40\n",
            "  Actual: 120000.00, Predicted: 79483.96\n",
            "  Actual: 312500.00, Predicted: 284921.37\n",
            "  Actual: 347000.00, Predicted: 335444.18\n",
            "  Actual: 253000.00, Predicted: 205063.49\n",
            "  Actual: 375000.00, Predicted: 506500.07\n",
            "  Actual: 235000.00, Predicted: 214339.15\n",
            "  Actual: 402000.00, Predicted: 387761.63\n",
            "\n",
            "Random Forest:\n",
            "Sample of 10 Actual Prices vs Predicted Prices:\n",
            "  Actual: 420000.00, Predicted: 589556.40\n",
            "  Actual: 715000.00, Predicted: 742503.88\n",
            "  Actual: 250000.00, Predicted: 324675.00\n",
            "  Actual: 120000.00, Predicted: 141030.00\n",
            "  Actual: 312500.00, Predicted: 370545.50\n",
            "  Actual: 347000.00, Predicted: 318471.60\n",
            "  Actual: 253000.00, Predicted: 250687.16\n",
            "  Actual: 375000.00, Predicted: 416730.00\n",
            "  Actual: 235000.00, Predicted: 253145.50\n",
            "  Actual: 402000.00, Predicted: 400125.57\n",
            "\n",
            "Gradient Boosting:\n",
            "Sample of 10 Actual Prices vs Predicted Prices:\n",
            "  Actual: 420000.00, Predicted: 644675.89\n",
            "  Actual: 715000.00, Predicted: 768144.94\n",
            "  Actual: 250000.00, Predicted: 342979.22\n",
            "  Actual: 120000.00, Predicted: 139439.92\n",
            "  Actual: 312500.00, Predicted: 335225.53\n",
            "  Actual: 347000.00, Predicted: 361548.74\n",
            "  Actual: 253000.00, Predicted: 240419.16\n",
            "  Actual: 375000.00, Predicted: 429967.58\n",
            "  Actual: 235000.00, Predicted: 259598.28\n",
            "  Actual: 402000.00, Predicted: 426518.69\n",
            "\n",
            "XGBoost:\n",
            "Sample of 10 Actual Prices vs Predicted Prices:\n",
            "  Actual: 420000.00, Predicted: 635606.65\n",
            "  Actual: 715000.00, Predicted: 748964.60\n",
            "  Actual: 250000.00, Predicted: 324338.36\n",
            "  Actual: 120000.00, Predicted: 162491.05\n",
            "  Actual: 312500.00, Predicted: 388158.10\n",
            "  Actual: 347000.00, Predicted: 311892.38\n",
            "  Actual: 253000.00, Predicted: 211581.62\n",
            "  Actual: 375000.00, Predicted: 375980.46\n",
            "  Actual: 235000.00, Predicted: 283503.22\n",
            "  Actual: 402000.00, Predicted: 411140.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bPsyDDemJoPy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yOjCgYtyJoNX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j2lV0L64JoK6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DGFgAKvDJoIT"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}